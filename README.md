
# Deep Image Colourisation:  comparing AutoEncoders and Conditional Adversarial Networks






## Overview
This repository contains code that was used to help me conduct my investigation for my dissertation.

This repository contains three folders:
- Documentation:
    - Contains the documentation details of this report, written in LaTeX.
- Notebooks:
    - Contains the prototype notebook, Results notebook & video colourisation notebook
    - Contains pre-trained models
    - Contains user study Results
    - Contains colourised images
- src:
    - Contains the models used for training.


## Acknowledgements
- This investigation uses code that does not belong to me. Here are the links to their repository:
    - deep koalorization (used for Simple AutoEncoder & Global AutoEncoder) : https://github.com/baldassarreFe/deep-koalarization
    - Pix2Pix : https://github.com/phillipi/pix2pix
    - ChromaGAN : https://github.com/pvitoria/ChromaGAN


## Prerequisites
- Python 3
- NVIDIA GPU + CUDA CuDNN
- Tensorflow 
- Keras
- openCV
- scikit-image
- places365 dataset, here's mine: https://drive.google.com/file/d/178mTebcMLPT5CixUzJOzoDYDLFpVIyNb/view?usp=sharing
- Get my trained models, here at: https://drive.google.com/drive/folders/1eFFwfeY66u_HgfBz8E3_gyNTXckASdSa?usp=sharing
    - place these models in /noteboks/trained_models








